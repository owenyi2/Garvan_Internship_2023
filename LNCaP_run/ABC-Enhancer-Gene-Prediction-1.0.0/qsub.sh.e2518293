Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 12
Rules claiming more threads will be scaled down.
Conda environments: ignored
Job stats:
job                             count
----------------------------  -------
all                                 1
call_macs_peaks                     1
create_neighborhoods                1
create_predictions                  1
filter_predictions                  1
generate_qc_plot_and_summary        1
make_candidate_regions              1
sort_narrowpeaks                    1
total                               8

Select jobs to execute...

[Thu Feb  1 13:46:41 2024]
rule call_macs_peaks:
    input: data/LNCaP_bam_files/USC20140207_DNase_LNCaP_24U.bam
    output: results/LNCaP/Peaks/macs2_peaks.narrowPeak
    jobid: 5
    reason: Software environment definition has changed since last execution
    wildcards: biosample=LNCaP
    resources: tmpdir=/scratch_local/2518293.1.short.q, mem_mb=33955, mem_mib=32383


		if [[ "data/LNCaP_bam_files/USC20140207_DNase_LNCaP_24U.bam" == *tagAlign* ]]; then
			FORMAT="BED"
		else
			FORMAT="AUTO"
		fi

		macs2 callpeak 		-f $FORMAT 		-g hs 		-p 0.1 		-n macs2 		--shift -75 		--extsize 150 		--nomodel 		--keep-dup all 		--call-summits 		--outdir results/LNCaP/Peaks 		-t data/LNCaP_bam_files/USC20140207_DNase_LNCaP_24U.bam 
		
INFO  @ Thu, 01 Feb 2024 13:46:42: 
# Command line: callpeak -f AUTO -g hs -p 0.1 -n macs2 --shift -75 --extsize 150 --nomodel --keep-dup all --call-summits --outdir results/LNCaP/Peaks -t data/LNCaP_bam_files/USC20140207_DNase_LNCaP_24U.bam
# ARGUMENTS LIST:
# name = macs2
# format = AUTO
# ChIP-seq file = ['data/LNCaP_bam_files/USC20140207_DNase_LNCaP_24U.bam']
# control file = None
# effective genome size = 2.70e+09
# band width = 300
# model fold = [5, 50]
# pvalue cutoff = 1.00e-01
# qvalue will not be calculated and reported as -1 in the final output.
# The maximum gap between significant sites is assigned as the read length/tag size.
# The minimum length of peaks is assigned as the predicted fragment length "d".
# Larger dataset will be scaled towards smaller dataset.
# Range for calculating regional lambda is: 10000 bps
# Broad region calling is off
# Paired-End mode is off
# Searching for subpeak summits is on
 
INFO  @ Thu, 01 Feb 2024 13:46:42: #1 read tag files... 
INFO  @ Thu, 01 Feb 2024 13:46:42: #1 read treatment tags... 
INFO  @ Thu, 01 Feb 2024 13:46:42: Detected format is: BAM 
INFO  @ Thu, 01 Feb 2024 13:46:42: * Input file is gzipped. 
INFO  @ Thu, 01 Feb 2024 13:46:45:  1000000 
INFO  @ Thu, 01 Feb 2024 13:46:47:  2000000 
INFO  @ Thu, 01 Feb 2024 13:46:48:  3000000 
INFO  @ Thu, 01 Feb 2024 13:46:50:  4000000 
INFO  @ Thu, 01 Feb 2024 13:46:52:  5000000 
INFO  @ Thu, 01 Feb 2024 13:46:53:  6000000 
INFO  @ Thu, 01 Feb 2024 13:46:55:  7000000 
INFO  @ Thu, 01 Feb 2024 13:46:56:  8000000 
INFO  @ Thu, 01 Feb 2024 13:46:58:  9000000 
INFO  @ Thu, 01 Feb 2024 13:47:00:  10000000 
INFO  @ Thu, 01 Feb 2024 13:47:02:  11000000 
INFO  @ Thu, 01 Feb 2024 13:47:03:  12000000 
INFO  @ Thu, 01 Feb 2024 13:47:05:  13000000 
INFO  @ Thu, 01 Feb 2024 13:47:06:  14000000 
INFO  @ Thu, 01 Feb 2024 13:47:08:  15000000 
INFO  @ Thu, 01 Feb 2024 13:47:10:  16000000 
INFO  @ Thu, 01 Feb 2024 13:47:11:  17000000 
INFO  @ Thu, 01 Feb 2024 13:47:13:  18000000 
INFO  @ Thu, 01 Feb 2024 13:47:14:  19000000 
INFO  @ Thu, 01 Feb 2024 13:47:16:  20000000 
INFO  @ Thu, 01 Feb 2024 13:47:18:  21000000 
INFO  @ Thu, 01 Feb 2024 13:47:20:  22000000 
INFO  @ Thu, 01 Feb 2024 13:47:21:  23000000 
INFO  @ Thu, 01 Feb 2024 13:47:23:  24000000 
INFO  @ Thu, 01 Feb 2024 13:47:24:  25000000 
INFO  @ Thu, 01 Feb 2024 13:47:26:  26000000 
INFO  @ Thu, 01 Feb 2024 13:47:28:  27000000 
INFO  @ Thu, 01 Feb 2024 13:47:29:  28000000 
INFO  @ Thu, 01 Feb 2024 13:47:31:  29000000 
INFO  @ Thu, 01 Feb 2024 13:47:32:  30000000 
INFO  @ Thu, 01 Feb 2024 13:47:34:  31000000 
INFO  @ Thu, 01 Feb 2024 13:47:36:  32000000 
INFO  @ Thu, 01 Feb 2024 13:47:37:  33000000 
INFO  @ Thu, 01 Feb 2024 13:47:39:  34000000 
INFO  @ Thu, 01 Feb 2024 13:47:40:  35000000 
INFO  @ Thu, 01 Feb 2024 13:47:42:  36000000 
INFO  @ Thu, 01 Feb 2024 13:47:44:  37000000 
INFO  @ Thu, 01 Feb 2024 13:47:45:  38000000 
INFO  @ Thu, 01 Feb 2024 13:47:47:  39000000 
INFO  @ Thu, 01 Feb 2024 13:47:48:  40000000 
INFO  @ Thu, 01 Feb 2024 13:47:50:  41000000 
INFO  @ Thu, 01 Feb 2024 13:47:52:  42000000 
INFO  @ Thu, 01 Feb 2024 13:47:54:  43000000 
INFO  @ Thu, 01 Feb 2024 13:47:55:  44000000 
INFO  @ Thu, 01 Feb 2024 13:47:57:  45000000 
INFO  @ Thu, 01 Feb 2024 13:47:58:  46000000 
INFO  @ Thu, 01 Feb 2024 13:48:00:  47000000 
INFO  @ Thu, 01 Feb 2024 13:48:02:  48000000 
INFO  @ Thu, 01 Feb 2024 13:48:03:  49000000 
INFO  @ Thu, 01 Feb 2024 13:48:05:  50000000 
INFO  @ Thu, 01 Feb 2024 13:48:06:  51000000 
INFO  @ Thu, 01 Feb 2024 13:48:08:  52000000 
INFO  @ Thu, 01 Feb 2024 13:48:10:  53000000 
INFO  @ Thu, 01 Feb 2024 13:48:11:  54000000 
INFO  @ Thu, 01 Feb 2024 13:48:13:  55000000 
INFO  @ Thu, 01 Feb 2024 13:48:15:  56000000 
INFO  @ Thu, 01 Feb 2024 13:48:17:  57000000 
INFO  @ Thu, 01 Feb 2024 13:48:18:  58000000 
INFO  @ Thu, 01 Feb 2024 13:48:20:  59000000 
INFO  @ Thu, 01 Feb 2024 13:48:22:  60000000 
INFO  @ Thu, 01 Feb 2024 13:48:23:  61000000 
INFO  @ Thu, 01 Feb 2024 13:48:25:  62000000 
INFO  @ Thu, 01 Feb 2024 13:48:27:  63000000 
INFO  @ Thu, 01 Feb 2024 13:48:28:  64000000 
INFO  @ Thu, 01 Feb 2024 13:48:30:  65000000 
INFO  @ Thu, 01 Feb 2024 13:48:31:  66000000 
INFO  @ Thu, 01 Feb 2024 13:48:33:  67000000 
INFO  @ Thu, 01 Feb 2024 13:48:35:  68000000 
INFO  @ Thu, 01 Feb 2024 13:48:36:  69000000 
INFO  @ Thu, 01 Feb 2024 13:48:38:  70000000 
INFO  @ Thu, 01 Feb 2024 13:48:39:  71000000 
INFO  @ Thu, 01 Feb 2024 13:48:41:  72000000 
INFO  @ Thu, 01 Feb 2024 13:48:43:  73000000 
INFO  @ Thu, 01 Feb 2024 13:48:44:  74000000 
INFO  @ Thu, 01 Feb 2024 13:48:46:  75000000 
INFO  @ Thu, 01 Feb 2024 13:48:47:  76000000 
INFO  @ Thu, 01 Feb 2024 13:48:49:  77000000 
INFO  @ Thu, 01 Feb 2024 13:48:51:  78000000 
INFO  @ Thu, 01 Feb 2024 13:48:52:  79000000 
INFO  @ Thu, 01 Feb 2024 13:48:54:  80000000 
INFO  @ Thu, 01 Feb 2024 13:48:56:  81000000 
INFO  @ Thu, 01 Feb 2024 13:48:58:  82000000 
INFO  @ Thu, 01 Feb 2024 13:49:00:  83000000 
INFO  @ Thu, 01 Feb 2024 13:49:02:  84000000 
INFO  @ Thu, 01 Feb 2024 13:49:03:  85000000 
INFO  @ Thu, 01 Feb 2024 13:49:05:  86000000 
INFO  @ Thu, 01 Feb 2024 13:49:07:  87000000 
INFO  @ Thu, 01 Feb 2024 13:49:08:  88000000 
INFO  @ Thu, 01 Feb 2024 13:49:10:  89000000 
INFO  @ Thu, 01 Feb 2024 13:49:11:  90000000 
INFO  @ Thu, 01 Feb 2024 13:49:13:  91000000 
INFO  @ Thu, 01 Feb 2024 13:49:15:  92000000 
INFO  @ Thu, 01 Feb 2024 13:49:16:  93000000 
INFO  @ Thu, 01 Feb 2024 13:49:18:  94000000 
INFO  @ Thu, 01 Feb 2024 13:49:19:  95000000 
INFO  @ Thu, 01 Feb 2024 13:49:21:  96000000 
INFO  @ Thu, 01 Feb 2024 13:49:23:  97000000 
INFO  @ Thu, 01 Feb 2024 13:49:24:  98000000 
INFO  @ Thu, 01 Feb 2024 13:49:26:  99000000 
INFO  @ Thu, 01 Feb 2024 13:49:28:  100000000 
INFO  @ Thu, 01 Feb 2024 13:49:29:  101000000 
INFO  @ Thu, 01 Feb 2024 13:49:31:  102000000 
INFO  @ Thu, 01 Feb 2024 13:49:33:  103000000 
INFO  @ Thu, 01 Feb 2024 13:49:34:  104000000 
INFO  @ Thu, 01 Feb 2024 13:49:36:  105000000 
INFO  @ Thu, 01 Feb 2024 13:49:38:  106000000 
INFO  @ Thu, 01 Feb 2024 13:49:39:  107000000 
INFO  @ Thu, 01 Feb 2024 13:49:41:  108000000 
INFO  @ Thu, 01 Feb 2024 13:49:42:  109000000 
INFO  @ Thu, 01 Feb 2024 13:49:44:  110000000 
INFO  @ Thu, 01 Feb 2024 13:49:46:  111000000 
INFO  @ Thu, 01 Feb 2024 13:49:47:  112000000 
INFO  @ Thu, 01 Feb 2024 13:49:49:  113000000 
INFO  @ Thu, 01 Feb 2024 13:49:50:  114000000 
INFO  @ Thu, 01 Feb 2024 13:49:52:  115000000 
INFO  @ Thu, 01 Feb 2024 13:49:54:  116000000 
INFO  @ Thu, 01 Feb 2024 13:49:55:  117000000 
INFO  @ Thu, 01 Feb 2024 13:49:57:  118000000 
INFO  @ Thu, 01 Feb 2024 13:49:59:  119000000 
INFO  @ Thu, 01 Feb 2024 13:50:01:  120000000 
INFO  @ Thu, 01 Feb 2024 13:50:02:  121000000 
INFO  @ Thu, 01 Feb 2024 13:50:04:  122000000 
INFO  @ Thu, 01 Feb 2024 13:50:06:  123000000 
INFO  @ Thu, 01 Feb 2024 13:50:07:  124000000 
INFO  @ Thu, 01 Feb 2024 13:50:09:  125000000 
INFO  @ Thu, 01 Feb 2024 13:50:10:  126000000 
INFO  @ Thu, 01 Feb 2024 13:50:12:  127000000 
INFO  @ Thu, 01 Feb 2024 13:50:14:  128000000 
INFO  @ Thu, 01 Feb 2024 13:50:15:  129000000 
INFO  @ Thu, 01 Feb 2024 13:50:17:  130000000 
INFO  @ Thu, 01 Feb 2024 13:50:19:  131000000 
INFO  @ Thu, 01 Feb 2024 13:50:20:  132000000 
INFO  @ Thu, 01 Feb 2024 13:50:22:  133000000 
INFO  @ Thu, 01 Feb 2024 13:50:23:  134000000 
INFO  @ Thu, 01 Feb 2024 13:50:25:  135000000 
INFO  @ Thu, 01 Feb 2024 13:50:27:  136000000 
INFO  @ Thu, 01 Feb 2024 13:50:28:  137000000 
INFO  @ Thu, 01 Feb 2024 13:50:30:  138000000 
INFO  @ Thu, 01 Feb 2024 13:50:32:  139000000 
INFO  @ Thu, 01 Feb 2024 13:50:34:  140000000 
INFO  @ Thu, 01 Feb 2024 13:50:35:  141000000 
INFO  @ Thu, 01 Feb 2024 13:50:37:  142000000 
INFO  @ Thu, 01 Feb 2024 13:50:39:  143000000 
INFO  @ Thu, 01 Feb 2024 13:50:40:  144000000 
INFO  @ Thu, 01 Feb 2024 13:50:42:  145000000 
INFO  @ Thu, 01 Feb 2024 13:50:43:  146000000 
INFO  @ Thu, 01 Feb 2024 13:50:45:  147000000 
INFO  @ Thu, 01 Feb 2024 13:50:47:  148000000 
INFO  @ Thu, 01 Feb 2024 13:50:48:  149000000 
INFO  @ Thu, 01 Feb 2024 13:50:50:  150000000 
INFO  @ Thu, 01 Feb 2024 13:50:51:  151000000 
INFO  @ Thu, 01 Feb 2024 13:50:53:  152000000 
INFO  @ Thu, 01 Feb 2024 13:50:55:  153000000 
INFO  @ Thu, 01 Feb 2024 13:50:56:  154000000 
INFO  @ Thu, 01 Feb 2024 13:50:58:  155000000 
INFO  @ Thu, 01 Feb 2024 13:51:00:  156000000 
INFO  @ Thu, 01 Feb 2024 13:51:01:  157000000 
INFO  @ Thu, 01 Feb 2024 13:51:03:  158000000 
INFO  @ Thu, 01 Feb 2024 13:51:04:  159000000 
INFO  @ Thu, 01 Feb 2024 13:51:06:  160000000 
INFO  @ Thu, 01 Feb 2024 13:51:07:  161000000 
INFO  @ Thu, 01 Feb 2024 13:51:09:  162000000 
INFO  @ Thu, 01 Feb 2024 13:51:10:  163000000 
INFO  @ Thu, 01 Feb 2024 13:51:12:  164000000 
INFO  @ Thu, 01 Feb 2024 13:51:26: 164923417 reads have been read. 
INFO  @ Thu, 01 Feb 2024 13:51:28: #1 tag size is determined as 50 bps 
INFO  @ Thu, 01 Feb 2024 13:51:28: #1 tag size = 50.0 
INFO  @ Thu, 01 Feb 2024 13:51:28: #1  total tags in treatment: 164923417 
INFO  @ Thu, 01 Feb 2024 13:51:28: #1 finished! 
INFO  @ Thu, 01 Feb 2024 13:51:28: #2 Build Peak Model... 
INFO  @ Thu, 01 Feb 2024 13:51:28: #2 Skipped... 
INFO  @ Thu, 01 Feb 2024 13:51:28: #2 Use 150 as fragment length 
INFO  @ Thu, 01 Feb 2024 13:51:28: #2 Sequencing ends will be shifted towards 5' by 75 bp(s) 
INFO  @ Thu, 01 Feb 2024 13:51:28: #3 Call peaks... 
INFO  @ Thu, 01 Feb 2024 13:51:28: #3 Going to call summits inside each peak ... 
INFO  @ Thu, 01 Feb 2024 13:51:28: #3 Call peaks with given -log10pvalue cutoff: 1.00000 ... 
INFO  @ Thu, 01 Feb 2024 13:51:28: #3 Pre-compute pvalue-qvalue table... 
INFO  @ Thu, 01 Feb 2024 13:58:02: #3 Call peaks for each chromosome... 
INFO  @ Thu, 01 Feb 2024 14:06:18: #4 Write output xls file... results/LNCaP/Peaks/macs2_peaks.xls 
INFO  @ Thu, 01 Feb 2024 14:06:23: #4 Write peak in narrowPeak format file... results/LNCaP/Peaks/macs2_peaks.narrowPeak 
INFO  @ Thu, 01 Feb 2024 14:06:26: #4 Write summits bed file... results/LNCaP/Peaks/macs2_summits.bed 
INFO  @ Thu, 01 Feb 2024 14:06:27: Done! 
[Thu Feb  1 14:06:28 2024]
Finished job 5.
1 of 8 steps (12%) done
Select jobs to execute...

[Thu Feb  1 14:06:28 2024]
rule sort_narrowpeaks:
    input: results/LNCaP/Peaks/macs2_peaks.narrowPeak, results/tmp/reference/hg38/GRCh38_EBV.no_alt.chrom.sizes.tsv.bed
    output: results/LNCaP/Peaks/macs2_peaks.narrowPeak.sorted
    jobid: 4
    reason: Input files updated by another job: results/LNCaP/Peaks/macs2_peaks.narrowPeak
    wildcards: biosample=LNCaP
    resources: tmpdir=/scratch_local/2518293.1.short.q, mem_mb=8000, mem_mib=7630


		# intersect to remove alternate chromosomes
		bedtools intersect -u -a results/LNCaP/Peaks/macs2_peaks.narrowPeak -b results/tmp/reference/hg38/GRCh38_EBV.no_alt.chrom.sizes.tsv.bed | 		bedtools sort -faidx reference/hg38/GRCh38_EBV.no_alt.chrom.sizes.tsv -i stdin > results/LNCaP/Peaks/macs2_peaks.narrowPeak.sorted
		
[Thu Feb  1 14:06:39 2024]
Finished job 4.
2 of 8 steps (25%) done
Select jobs to execute...

[Thu Feb  1 14:06:39 2024]
rule make_candidate_regions:
    input: results/LNCaP/Peaks/macs2_peaks.narrowPeak.sorted, data/LNCaP_bam_files/USC20140207_DNase_LNCaP_24U.bam, results/tmp/reference/hg38/GRCh38_EBV.no_alt.chrom.sizes.tsv.bed
    output: results/LNCaP/Peaks/macs2_peaks.narrowPeak.sorted.candidateRegions.bed
    jobid: 3
    reason: Input files updated by another job: results/LNCaP/Peaks/macs2_peaks.narrowPeak.sorted
    wildcards: biosample=LNCaP
    resources: tmpdir=/scratch_local/2518293.1.short.q, mem_mb=34320, mem_mib=32731


		python workflow/scripts/makeCandidateRegions.py 			--narrowPeak results/LNCaP/Peaks/macs2_peaks.narrowPeak.sorted			--accessibility data/LNCaP_bam_files/USC20140207_DNase_LNCaP_24U.bam 			--outDir results/LNCaP/Peaks 			--chrom_sizes reference/hg38/GRCh38_EBV.no_alt.chrom.sizes.tsv 			--chrom_sizes_bed results/tmp/reference/hg38/GRCh38_EBV.no_alt.chrom.sizes.tsv.bed 			--regions_blocklist reference/hg38/GRCh38_unified_blacklist.bed 			--regions_includelist reference/hg38/CollapsedGeneBounds.hg38.TSS500bp.bed 			--peakExtendFromSummit 250 			--nStrongestPeak 150000
		
[Thu Feb  1 14:17:51 2024]
Finished job 3.
3 of 8 steps (38%) done
Select jobs to execute...

[Thu Feb  1 14:17:51 2024]
rule create_neighborhoods:
    input: results/LNCaP/Peaks/macs2_peaks.narrowPeak.sorted.candidateRegions.bed, results/tmp/reference/hg38/GRCh38_EBV.no_alt.chrom.sizes.tsv.bed
    output: results/LNCaP/Neighborhoods/EnhancerList.txt, results/LNCaP/Neighborhoods/GeneList.txt, results/LNCaP/Neighborhoods, results/LNCaP/processed_genes_file.bed
    jobid: 2
    reason: Input files updated by another job: results/LNCaP/Peaks/macs2_peaks.narrowPeak.sorted.candidateRegions.bed
    wildcards: biosample=LNCaP
    resources: tmpdir=/scratch_local/2518293.1.short.q, mem_mb=32000, mem_mib=30518


		# get sorted & unique gene list
		# intersect first to remove alternate chromosomes
		bedtools intersect -u -a reference/hg38/CollapsedGeneBounds.hg38.bed -b results/tmp/reference/hg38/GRCh38_EBV.no_alt.chrom.sizes.tsv.bed | 		bedtools sort -faidx reference/hg38/GRCh38_EBV.no_alt.chrom.sizes.tsv -i stdin | 		uniq > results/LNCaP/processed_genes_file.bed
						
		python workflow/scripts/run.neighborhoods.py 			--candidate_enhancer_regions results/LNCaP/Peaks/macs2_peaks.narrowPeak.sorted.candidateRegions.bed 			--DHS data/LNCaP_bam_files/USC20140207_DNase_LNCaP_24U.bam 			--ATAC  			--default_accessibility_feature DHS 			--chrom_sizes reference/hg38/GRCh38_EBV.no_alt.chrom.sizes.tsv 			--chrom_sizes_bed results/tmp/reference/hg38/GRCh38_EBV.no_alt.chrom.sizes.tsv.bed 			--outdir results/LNCaP/Neighborhoods 			--genes results/LNCaP/processed_genes_file.bed 			--ubiquitously_expressed_genes reference/UbiquitouslyExpressedGenes.txt 			--qnorm reference/EnhancersQNormRef.K562.txt 			--H3K27ac data/LNCaP_bam_files/USC20130125_LNCaP_H3K27ac.bam
		
/home/oweyi/Garvan_Internship_2023/LNCaP_run/ABC-Enhancer-Gene-Prediction-1.0.0/workflow/scripts/run.neighborhoods.py:4: DeprecationWarning: 
Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),
(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)
but was not found to be installed on your system.
If this would cause problems for you,
please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466
        
  import pandas as pd
/home/oweyi/micromamba/envs/abc-env-1/lib/python3.10/site-packages/pyranges/methods/init.py:45: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  return {k: v for k, v in df.groupby(grpby_key)}
/home/oweyi/micromamba/envs/abc-env-1/lib/python3.10/site-packages/pyranges/methods/init.py:45: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  return {k: v for k, v in df.groupby(grpby_key)}
/home/oweyi/micromamba/envs/abc-env-1/lib/python3.10/site-packages/pyranges/methods/init.py:45: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  return {k: v for k, v in df.groupby(grpby_key)}
/home/oweyi/micromamba/envs/abc-env-1/lib/python3.10/site-packages/pyranges/methods/init.py:45: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  return {k: v for k, v in df.groupby(grpby_key)}
[Thu Feb  1 14:22:24 2024]
Finished job 2.
4 of 8 steps (50%) done
Select jobs to execute...

[Thu Feb  1 14:22:24 2024]
rule create_predictions:
    input: results/LNCaP/Neighborhoods/EnhancerList.txt, results/LNCaP/Neighborhoods/GeneList.txt
    output: results/LNCaP/Predictions/EnhancerPredictionsAllPutative.tsv.gz, results/LNCaP/Predictions/EnhancerPredictionsAllPutativeNonExpressedGenes.tsv.gz
    jobid: 1
    reason: Missing output files: results/LNCaP/Predictions/EnhancerPredictionsAllPutativeNonExpressedGenes.tsv.gz, results/LNCaP/Predictions/EnhancerPredictionsAllPutative.tsv.gz; Input files updated by another job: results/LNCaP/Neighborhoods/GeneList.txt, results/LNCaP/Neighborhoods/EnhancerList.txt
    wildcards: biosample=LNCaP
    resources: tmpdir=/scratch_local/2518293.1.short.q, mem_mb=32000, mem_mib=30518


		python workflow/scripts/predict.py 			--enhancers results/LNCaP/Neighborhoods/EnhancerList.txt 			--outdir results/LNCaP/Predictions 			--score_column ABC.Score 			--chrom_sizes reference/hg38/GRCh38_EBV.no_alt.chrom.sizes.tsv 			--accessibility_feature DHS 			--cellType LNCaP 			--genes results/LNCaP/Neighborhoods/GeneList.txt 			--hic_gamma 1.024238616787792 			--hic_scale 5.9594510043736655 			--hic_file ../data/avg_hic_juicebox/ --hic_type juicebox --hic_resolution 5000 			--scale_hic_using_powerlaw
		
/home/oweyi/Garvan_Internship_2023/LNCaP_run/ABC-Enhancer-Gene-Prediction-1.0.0/workflow/scripts/predict.py:6: DeprecationWarning: 
Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),
(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)
but was not found to be installed on your system.
If this would cause problems for you,
please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466
        
  import pandas as pd
/home/oweyi/micromamba/envs/abc-env-1/lib/python3.10/site-packages/pyranges/methods/init.py:45: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  return {k: v for k, v in df.groupby(grpby_key)}
/home/oweyi/micromamba/envs/abc-env-1/lib/python3.10/site-packages/pyranges/methods/init.py:45: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  return {k: v for k, v in df.groupby(grpby_key)}
Traceback (most recent call last):
  File "/home/oweyi/Garvan_Internship_2023/LNCaP_run/ABC-Enhancer-Gene-Prediction-1.0.0/workflow/scripts/predict.py", line 303, in <module>
    main()
  File "/home/oweyi/Garvan_Internship_2023/LNCaP_run/ABC-Enhancer-Gene-Prediction-1.0.0/workflow/scripts/predict.py", line 242, in main
    this_chr = make_predictions(
  File "/home/oweyi/Garvan_Internship_2023/LNCaP_run/ABC-Enhancer-Gene-Prediction-1.0.0/workflow/scripts/predictor.py", line 32, in make_predictions
    pred = add_hic_from_directory(
  File "/home/oweyi/Garvan_Internship_2023/LNCaP_run/ABC-Enhancer-Gene-Prediction-1.0.0/workflow/scripts/predictor.py", line 172, in add_hic_from_directory
    hic_file, hic_norm_file, hic_is_vc = get_hic_file(
  File "/home/oweyi/Garvan_Internship_2023/LNCaP_run/ABC-Enhancer-Gene-Prediction-1.0.0/workflow/scripts/hic.py", line 33, in get_hic_file
    raise RuntimeError(
RuntimeError: Could not find KR, INTERSCALE or VC normalized hic files
[Thu Feb  1 14:22:29 2024]
Error in rule create_predictions:
    jobid: 1
    input: results/LNCaP/Neighborhoods/EnhancerList.txt, results/LNCaP/Neighborhoods/GeneList.txt
    output: results/LNCaP/Predictions/EnhancerPredictionsAllPutative.tsv.gz, results/LNCaP/Predictions/EnhancerPredictionsAllPutativeNonExpressedGenes.tsv.gz
    conda-env: /home/oweyi/Garvan_Internship_2023/LNCaP_run/ABC-Enhancer-Gene-Prediction-1.0.0/.snakemake/conda/29c2445ddeb26f09d15e84697767902e_
    shell:
        
		python workflow/scripts/predict.py 			--enhancers results/LNCaP/Neighborhoods/EnhancerList.txt 			--outdir results/LNCaP/Predictions 			--score_column ABC.Score 			--chrom_sizes reference/hg38/GRCh38_EBV.no_alt.chrom.sizes.tsv 			--accessibility_feature DHS 			--cellType LNCaP 			--genes results/LNCaP/Neighborhoods/GeneList.txt 			--hic_gamma 1.024238616787792 			--hic_scale 5.9594510043736655 			--hic_file ../data/avg_hic_juicebox/ --hic_type juicebox --hic_resolution 5000 			--scale_hic_using_powerlaw
		
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: .snakemake/log/2024-02-01T134637.296353.snakemake.log
